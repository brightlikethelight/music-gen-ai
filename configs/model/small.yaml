# Small model configuration for faster training/inference

# @package _global_
defaults:
  - base

size: small
hidden_size: 512
num_layers: 8  
num_heads: 8
intermediate_size: 2048
max_sequence_length: 4096
max_generation_length: 2048

# Enable optimizations for smaller model
gradient_checkpointing: false
use_scaled_dot_product_attention: true

# Smaller conditioning
conditioning_dim: 256